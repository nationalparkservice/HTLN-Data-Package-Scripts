# install.packages("devtools")
devtools::install_github("nationalparkservice/QCkit")
1
options(download.file.method = “wininet”)
options(download.file.method = “wininet”)
options(download.file.method = “wininet”)
options(download.file.method = "wininet")
devtools::install_github("nationalparkservice/NPSdataverse")
devtools::install_github("nationalparkservice/NPSdataverse")
install.packages("vctrs")
devtools::install_github("nationalparkservice/NPSdataverse")
options(download.file.method = "wininet")
devtools::install_github("nationalparkservice/NPSdataverse")
library(NPSdataverse)
library(tidyverse)
library(tidyverse)
mydata <- read_csv("./src/TreeTally.csv")
# NPS-EML-Creation-Workflow.R
# Summary
# This script acts as a template file for end-to-end creation of EML metadata in R for DataStore.
# The metadata generated will be of sufficient quality for the Data Package Reference
# Type and can be used to automatically populate the DataStore fields for this reference type.
# The script utilizes multiple R packages and the example inputs are for an EVER Veg Map AA dataset.
# The example script is meant to either be run as a test of the process
# or to be replaced with your own content. This is a step by step process where each section
# (indicated by dashed lines) should be reviewed, edited if necessary, and run one at a time.
# After completing a section there is often something to do external to R (e.g. open a text file and add content).
# Several EMLassemblyline functions are decision points and may only apply to certain data packages.
# This workflow takes advantage of the NPSdataverse, an R-based ecosystem that includes external EML
# creation tools such as the R packages EMLassemblyline and EML. However, these tools were not designed
# to work with DataStore. Therefore, the NPSdatavers and this workflow also incorporate steps
# from NPS-developed R packages such as EMLeditor and DPchecker. You will necessarily
# over-write some of the information generated by EMLassemblyline. That is OK and is expected behavior.
# Good additional references
# [EMLassemblyline](https://ediorg.github.io/EMLassemblyline/)
# [EMLeditor](https://nationalparkservice.github.io/EMLeditor/index.html)
# [NPS EML Script](https://nationalparkservice.github.io/NPS_EML_Script/)
# [EVER Veg Map AA dataset](https://github.com/nationalparkservice/NPS_EML_Script/tree/main/Example_files) (for testing purposes)
# Install and Load R Packages
# Install packages. If you have not recently installed packages, please re-install them.
# You will want to make sure you have the latest versions of all the NPSdataverse packages -
# QCkit, EMLeditor, DPchecker, and NPSutils - as they are under constant development.
# If you are on the VPN, you will need to set your CRAN mirror to Texas 1. If you run
# into errors installing packages from github on NPS computers you may first need to run:
# options(download.file.method="wininet")
# install packages
# install.packages(c("devtools", "tidyverse")
# devtools::install_github("nationalparkservice/NPSdataverse")
# When loading packages, you may be advised to update to more recent versions
# of dependent packages. Most of these updates likely are not critical.
# However, it is important that you update to the latest versions of QCkit,
# EMLeditor, DPchecker and NPSutils as these NPS packages are under constant
# development.
library(NPSdataverse)
library(tidyverse)
############################################
# OBJECT ASSIGNMENT
# Set the overall package details
# All of the following items should be reviewed and updated to fit the package you
# are working on. For lists of more than one item, keep the same order (i.e. item #1
# should correspond to the same file in each list).
#### Metadata filename
# This becomes the file name of your .xml file. Be sure it ends in _metadata to
# comply with data package specifications. You do not need to include the extension (.xml).
metadata_id <- "HTLN-BreedingBird-Metadata"
#### Package Title
# Give the data package a title. FAIR principles suggest titles of between 7 and 20 words.
# Be sure to make your title informative and consider how a naive user would interpret it.
package_title <- "Heartland I&M Network Breeding Bird Data Package"
#### Data collection status
# Choose from either "ongoing" or "complete"
data_type <- "ongoing"
#### Path to data file(s)
# Tell R where your data files are. If they are in the working directory, you can
# set the working_folder to `getwd()`. If they are in a different directory you will
# need to specify that directory.
working_folder <- setwd("./Package")
getwd()
# NPS-EML-Creation-Workflow.R
# Summary
# This script acts as a template file for end-to-end creation of EML metadata in R for DataStore.
# The metadata generated will be of sufficient quality for the Data Package Reference
# Type and can be used to automatically populate the DataStore fields for this reference type.
# The script utilizes multiple R packages and the example inputs are for an EVER Veg Map AA dataset.
# The example script is meant to either be run as a test of the process
# or to be replaced with your own content. This is a step by step process where each section
# (indicated by dashed lines) should be reviewed, edited if necessary, and run one at a time.
# After completing a section there is often something to do external to R (e.g. open a text file and add content).
# Several EMLassemblyline functions are decision points and may only apply to certain data packages.
# This workflow takes advantage of the NPSdataverse, an R-based ecosystem that includes external EML
# creation tools such as the R packages EMLassemblyline and EML. However, these tools were not designed
# to work with DataStore. Therefore, the NPSdatavers and this workflow also incorporate steps
# from NPS-developed R packages such as EMLeditor and DPchecker. You will necessarily
# over-write some of the information generated by EMLassemblyline. That is OK and is expected behavior.
# Good additional references
# [EMLassemblyline](https://ediorg.github.io/EMLassemblyline/)
# [EMLeditor](https://nationalparkservice.github.io/EMLeditor/index.html)
# [NPS EML Script](https://nationalparkservice.github.io/NPS_EML_Script/)
# [EVER Veg Map AA dataset](https://github.com/nationalparkservice/NPS_EML_Script/tree/main/Example_files)
# (for testing purposes)
# Install and Load R Packages
# Install packages. If you have not recently installed packages, please re-install them.
# You will want to make sure you have the latest versions of all the NPSdataverse packages -
# QCkit, EMLeditor, DPchecker, and NPSutils - as they are under constant development.
# If you are on the VPN, you will need to set your CRAN mirror to Texas 1. If you run
# into errors installing packages from github on NPS computers you may first need to run:
# options(download.file.method="wininet")
# install packages
# install.packages(c("devtools", "tidyverse")
# devtools::install_github("nationalparkservice/NPSdataverse")
# When loading packages, you may be advised to update to more recent versions
# of dependent packages. Most of these updates likely are not critical.
# However, it is important that you update to the latest versions of QCkit,
# EMLeditor, DPchecker and NPSutils as these NPS packages are under constant
# development.
library(NPSdataverse)
library(tidyverse)
############################################
# OBJECT ASSIGNMENT
# Set the overall package details
# All of the following items should be reviewed and updated to fit the package you
# are working on. For lists of more than one item, keep the same order (i.e. item #1
# should correspond to the same file in each list).
#### Metadata filename
# This becomes the file name of your .xml file. Be sure it ends in _metadata to
# comply with data package specifications. You do not need to include the extension (.xml).
metadata_id <- "HTLN-BreedingBird-Metadata"
#### Package Title
# Give the data package a title. FAIR principles suggest titles of between 7 and 20 words.
# Be sure to make your title informative and consider how a naive user would interpret it.
package_title <- "Heartland I&M Network Breeding Bird Data Package"
#### Data collection status
# Choose from either "ongoing" or "complete"
data_type <- "ongoing"
#### Path to data file(s)
# Tell R where your data files are. If they are in the working directory, you can
# set the working_folder to `getwd()`. If they are in a different directory you will
# need to specify that directory.
working_folder <- setwd("C:/users/growell/HTLN-BreedingBird-Data-Package/src")
# or:
# working_folder <- setwd("C:/users/<yourusername>/Documents/my_data_package_folder)
#### List data files
# Tell R what your data files are called.
data_files <- c("BasalArea.csv",
"BirdObservationsThru2022_3.csv",
"CanopyCover.csv",
"CanopyHeight.csv",
"FoliarCover.csv",
"GroundCover.csv",
"HorizDistanceProfile.csv",
"PlotCoordinatesDD.csv",
"PlotPhysicalFeatures.csv",
"PlotVegCover.csv",
"TreeTally.csv",
"VerticalProfile.csv")
# alternatively if the data files are in your working directory:
# data_files <- list.files(pattern = "*.csv")
#### Name the data files
# These should be relatively short, but perhaps more informative than the actual file names.
# Make sure that they are in the same order as the files in data_files.
data_names <- c("Habitat - BasalArea Data",
"Bird Observations - Site Conditions Data",
"Habitat - Canopy Cover Data",
"Habitat - Canopy Height Data",
"Habitat - Foliar Cover Data",
"Habitat - Ground Cover Data",
"Habitat - Horizontal Distance Profile Data",
"Sampling Plot Coordinates",
"Habitat - Plot Physical Features Data",
"Habitat - Plot Vegetation Cover Data",
"Habitat - Tree Tally Data",
"Habitat - Vertical Profile Data")
#### Describe each data file. Data file descriptions should be unique and about 10 words long.
# Descriptions will be used in auto-generated tables within the ReadMe and DRR.
# If you need to use more than 10 words, consider putting that information into the abstract,
# methods, or additional information sections. Again, make sure these are in the same order as
# the files they are describing.
data_descriptions <- c("Basal area of hardwood and conifer species estimated using a 10-factor English cruz-all",
"Bird observations taken using variable circular plots using continuous distance",
"Canopy cover estimated with densiometer at four cardinal directions (N, E, S, W)",
"Canopy heights of the tallest hardwood and coniferous trees estimated with clinometer",
"Percent foliar cover estimated under 1.5 high grouped into plant guilds",
"Percent ground cover estimated for conifer, deciduous, grass litter, rock and other classes",
"Horizontal vegetation profile readings taken using profile board at 15 m.",
"Sampling Plot Coordinates in latitude - longitude decimal degrees",
"Plot physical attributes including slope, aspect, and topographic description",
"Plot cover types estimated by percent cover classes",
"Tree tally data for tree species > 1.5 m based on diameter size-classes",
"Vertical profile of vegetion measured with 7.5 m rod")
#### Placeholder URL for data files
# EMLassemblyline needs to know where the data files will be (a URL). However, because you
# have not yet initiated a draft reference in DataStore, it isn't possible to specify a URL.
# Instead, insert a place holder. Don't worry - this information will be updated later on when
# you add a Digital Object Identifier(DOI) to the metadata.
data_urls <- c(rep("temporary URL", length(data_files)))
#### Taxonomic information
# Specify where you taxonomic information is. this can be a single file or a list of
# files and fields (columns) with scientific names that will be used to automatically
# generate the taxonomic coverage metadata. We suggest using [DarwinCore](https://dwc.tdwg.org/terms)
# for column names, such as "scientificName". If your data package does not have
# taxonomic data, skip this step.```{r taxonomic_info}
# the file(s) where scientific names are located:
data_taxa_tables <- c("BirdSpeciesNames.csv","TreeSpeciesNames.csv")
# the column where your scientific names are within the data files.
data_taxa_fields <- c("ScientificName","ScientificName")
#### Geographic information
# Specify the tables and fields that contain geographic coordinates
# and site names. This information will be used to fill out the
# geographic coverage elements of the metadata. If your data package
# does not have geographic information skip this step. If the only geographic
# information you are supplying is the park units (and their bounding boxes)
# you can also skip this step; Park Units and the corresponding GPS
# coordinates for their bounding boxes will be added at a later step.
# If your coordinates are in UTMs and not GPS, try the [`convert_utm_to_ll()`]
# (https://nationalparkservice.github.io/QCkit/reference/convert_utm_to_ll.html)
# function in the [QCkit package](https://nationalparkservice.github.io/QCkit/)
data_coordinates_table <- "PlotCoodinatesDD.csv"
data_latitutde <- "decimalLatitude"
data_longitude <- "decimalLongitude"
data_sitename <- "PlotID"
#### Temporal information
# This should indicate collection date of the first and last data point in the
# data package (across all files) and does not include any planning, pre- or
# post-processing time. The format should be one that complies with the
# International Standards Organization's standard 8601. The recommended format for
# EML is: YYYY-MM-DD, where Y is the four digit year, M is the two digit month
# code (01 - 12 for example, January = 01), and D is the two digit day of the
# month (01 - 31). Using an alternate format or setting the date to the future
# will cause errors down the road!
startdate <- ymd("2001-05-07")
enddate <- ymd("2022-06-15")
######################################################################################
## EMLassemblyline Functions
# The next set of functions are meant to be considered one by one and only run if
# applicable to a particular data package. The first year will typically see all of
# these run, but if the data format and protocol stay constant over time it may be
# possible to skip some in future years. Additionally some datasets may not have
# geographic or taxonomic component.
#### FUNCTION 1 - Core Metadata Information
# This function creates blank .txt template files for the abstract, additional information,
# custom units, intellectual rights, keywords, methods, and personnel. Be sure the edit the
# personnel text file in Excel as it has columns. Remember that the role "creator" is required!
# EMLassemblyline will also warn you if you do not include a "PI" role, but you can
# ignore the warning; this role is not required. Typically these files can be reused between years.
# We encourage you to craft your abstract in a text editor, NOT Word. Your abstract will be
# forwarded to data.gov, DataCite, google dataset search, etc. so it is worth some time to
# carefully consider what is relevant and important information for an abstract. Abstracts
# must be greater than 20 words. Good abstracts tend to be 250 words or less. You may consider
# including the following information: The premise for the data collection (why was it done?),
# why is it important, a brief overview of relevant methods, and a brief explanation of what
# data are included such as the period of time, location(s), and type of data collected. Keep
# in mind that if you have lengthy descriptions of methods, provenance, data QA/QC, etc it
# may be better to expand upon these topics in a Data Release Report or similar document uploaded
# separately to DataStore.
# Currently this function inserts a Creative Common 0 license. The CC0 license will need to be
# updated. However, to ensure that the licence meets NPS specifications and properly
# coincides with CUI designations, the best way to update the license information is during a
# later step using `EMLeditor::set_int_rights()`. There is no need to edit this .txt file.
#template_core_metadata(path = working_folder,
#                       license = "CC0") # that '0' is a zero!
#### FUNCTION 2 - Data Table Attributes
# This function creates an "attributes_datafilename.txt" file for each data file. This can be opened
# in Excel (we recommend against trying to update these in a text editor) and fill in/adjust the
# columns for attributeDefinition, class, unit, etc.
# refer to https://ediorg.github.io/EMLassemblyline/articles/edit_tmplts.html for helpful hints and `view_unit_dictionary()` for potential units. This will only need to be run again if the attributes (name, order or new/deleted fields) are modified from the previous year. NOTE that if these files already exist from a previous run, they are not overwritten.
#working_folder <- setwd("C:/users/growell/HTLN-BreedingBird-Data-Package/src")
#template_table_attributes(path = working_folder,
#                          data.table = data_files,
#                          write.file = TRUE)
#### FUNCTION 3 - Data Table Categorical Variable
# This function Creates a "catvars_datafilename.txt" file for each data file that
# has columns with a class = categorical. These .txt files will include each unique
# 'code' and allow input of the corresponding 'definition'.NOTE that since the list
# of codes is harvested from the data itself, it's possible that additional codes
# may have been relevant/possible but they are not automatically included here.
# Consider your lookup lists carefully to see if additional options should be included
# (e.g if your dataset DPL values are all set to "Accepted" this  function will not
# include "Raw" or "Provisional" in the resulting file and you may want to add those
# manually). NOTE that if these files already exist from a previous run, they
# are not overwritten.
#template_categorical_variables(path = working_folder,
#data.path = working_folder,
#write.file = TRUE)
#### FUNCTION 4 - Geographic Coverage
# If the only geographic coverage information you plan on using are park boundaries,
# you can skip this step. You can add park unit connections using EMLeditor, which will automatically generate properly formatted GPS coordinates for the park bounding boxes.
# If you would like to add additional GPS coordinates (such as for specific site
# locations, survey plots, or bounding boxes for locations within a park, etc) please do.
# This function creates a geographic_coverage.txt file that lists your sites as points as long as your coordinates are in lat/long. If your coordinates are in UTM it is probably easiest to convert them first or create the geographic_coverage.txt file another way (see [QCkit](https://nationalparkservice.github.io/QCkit/) for R functions that will convert UTM to lat/long).
#template_geographic_coverage(path = working_folder,
#                             data.path = working_folder,
#                             data.table = data_coordinates_table,
#                             lat.col = data_latitude,
#                             lon.col = data_longitude,
#                             site.col = data_sitename,
#                             write.file = TRUE)
#### FUNCTION 5 - Taxonomic Coverage
# This function creates a taxonomic_coverage.txt file if you have taxonomic data.
# Currently supported authorities are 3 = ITIS, 9 = WORMS, and 11 = GBIF.
# In the example below, the function will first try to find the scientific name
# at ITIS and if it fails will then look at GBIF. If you have lots of taxa,
# this could take some time to
# working_folder <- setwd("C:/users/growell/HTLN-BreedingBird-Data-Package/src")
# template_taxonomic_coverage(path = working_folder,
#                            data.path = working_folder,
#                            taxa.table = data_taxa_tables,
#                            taxa.col = data_taxa_fields,
#                            taxa.authority = c(3,11),
#                            taxa.name.type = 'scientific',
#                            write.file = TRUE)
## Create an EML File - ##############################################################
# Run this (it may take a little while) and see if it validates (you should see
# 'Validation passed'). It will generate an R object called "my_metadata". The
# function could alert you of some issues to review as. Run the function `issues()`
# at the end of the process to get feedback on items that might be missing or need
# attention. Fix these issues and then re-run the `make_eml()` function.
working_folder <- setwd("C:/users/growell/HTLN-BreedingBird-Data-Package/src")
# Missing element for publication date. Check original script <<<<<<<<<<<<<<<
# There is nothing to specify pub. date in this script
my_metadata <- make_eml(path = working_folder,
dataset.title = package_title,
data.table = data_files,
data.table.name = data_names,
data.table.description = data_descriptions,
data.table.url = data_urls,
temporal.coverage = c(startdate, enddate),
maintenance.description = data_type,
package.id = metadata_id,
return.obj = TRUE,
write.file = FALSE)
